# ChatPartner - 语音聊天助手

一个可以语音对话的AI助手，支持实时语音交流，就像和真人聊天一样。

- 你计划将这个网页面向什么类型的用户？
  - 答：任何人都能使用，不同的提示词可以让AI充当各种角色。提供各种回答帮助或者是陪伴帮助。

- 这些类型的用户他们面临什么样的痛点，你设想的用户故事是什么样呢？
  - 答：也许是AI使用不方便，或者难以管理AI，当处理不同场景的问题时，需要构造prompt让自己不方便，那么该系统可以让自己同时拥有多个角色的AI，快速特定的处理不同场景的问题，而语音聊天更是一大亮点，方便又亲切。

- 你认为这个网页需要哪些功能？这些功能各自的优先级是什么？
  - 答：LLM模型对话 => 聊天记忆 => 管理会话 => 不同角色 => 角色管理、好友管理 => 语音聊天 => AI角色的知识库、工具调用集成管理。

- 你计划本次开发哪些功能？你计划采纳哪家公司的哪个 LLM 模型能力？你对比了哪些，你为什么选择用该 LLM 模型？
  - 上述的都想开发，但实际时间，并没有开发到管理不同的知识库，工具调用等。modelscope魔搭社区的deepseek，有免费额度又好用，方便开发..后面改成了glm4.5，这些都是平价里的能力不错的模型

- 你期望 AI 角色除了语音聊天外还应该有哪些技能？
  - 自定义集成知识库，调节语音对话音色，提供mcp、工具仓库，可自行配置角色的mcp和工具调用能力等，如果是特定的项目，我希望还可以结合具体的业务系统，能够有操作业务系统的能力，可以把业务操作当成是工具，在保证经过了用户的二次确认的情况下，可以操作业务逻辑，帮助用户完成操作等...

## 快速开始

### 第一步：配置AI模型

在 `src/main/resources` 文件夹里创建 `application-local.yml` 文件，填入你的AI配置：

```yaml
# AI模型配置（必填）
ai:
  base-url: "你的AI服务地址"    # 比如：https://api.deepseek.com/v1
  api-key: "你的API密钥"       # 从AI服务商那里获取
  model: "模型名称"            # 比如：deepseek-v3
```

> 💡 我们默认用的是DeepSeek，你也可以换成其他支持OpenAI格式的AI服务

---

### 第二步：配置语音服务（可选）

如果你想用语音对话功能，需要申请七牛云的语音服务：

```yaml
# 七牛云语音服务（语音对话需要）
qiniu:
  api-key: "你的七牛云密钥"
```

## 运行项目

### 准备工作

你需要安装：
- Java 21
- Node.js 22
- MySQL、Redis

**1. 启动后端**

```bash
./mvnw spring-boot:run -Dspring-boot.run.profiles=local
```

**2. 启动前端**

```bash
cd chat-partner-frontend
npm install
npm run dev
```

**3. 打开浏览器**

访问 `http://localhost:5173` 就可以开始聊天了！

---

## 项目特色

### 🎯 主要功能
- **语音对话**：像打电话一样和AI聊天
- **文字聊天**：传统的打字聊天方式  
- **多角色**：可以和不同性格的AI角色对话
- **实时响应**：AI边想边说，不用等很久

### 🛠️ 技术特点
- **纯净架构**：不依赖第三方AI平台，完全自主可控
- **实时流式**：从说话到听到回复，全程流畅无卡顿
- **开发友好**：代码结构清晰，容易修改和扩展

## 技术架构

### 🏗️ 语音聊天实现原理
```
用户说话 → 浏览器录音 → WebSocket传输 → 七牛ASR识别 → 
AI流式生成 → 文本分句 → 七牛TTS合成 → 音频流返回 → 浏览器播放
```

### 🎙️ 核心实现

#### 1. 前端音频处理
```javascript
// 浏览器录音：16kHz/16bit/mono PCM
navigator.mediaDevices.getUserMedia({ audio: true })
// 实时传输音频数据到后端
websocket.send(pcmAudioData)
```

#### 2. 后端流式处理
```java
@Component
public class VoiceStreamHandler {
    // WebSocket接收音频 → 七牛ASR → LLM流式生成 → TTS合成
    // 全程流式处理，最小化延迟
}
```

#### 3. 关键技术点
- **实时音频流**：浏览器 ↔ 后端 WebSocket 双向通信
- **流式AI生成**：LLM token 逐个生成，边生成边合成语音
- **智能分句**：按标点符号切分，每句话独立TTS合成
- **背压控制**：防止音频积压，保证实时性

### 🔧 技术栈
- **后端**：Spring Boot + WebSocket + LangChain4j
- **前端**：Vue 3 + Web Audio API
- **AI模型**：支持OpenAI格式的任意LLM
- **语音服务**：七牛云 ASR + TTS
- **数据库**：MySQL + Redis
